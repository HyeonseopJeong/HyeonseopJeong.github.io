---
layout: post
title: ["[특강] 데이터의 미래"]
description: 최희열교수님 특강
tags: ["특강", "AI"]
author: Hyeonseop Jeong
comments : True
post : false
---

# ai
ai가 비약적으로 다시 상승하게 된 계기가 머신러닝이 나오고 부터인데 그 이유는 머신러닝은 다른 ai 방식들과는 다르게 데이터를 샘플링 할 필요 없이 데이터가 많이 들어오면 많이 들어올 수 록 좋은 방식이기 때문이다. (빅데이터를 그냥 때려박으면 되는건가?)


# 데이터의 특징
데이터는 구조적인 데이터와 비구조적인 데이터로 나눌 수 있다.

대충 엑셀로 정리해서 평균, 분산을 구할 수 있으면 구조적인 데이터라고 하고 아니면 비구조적인 데이터라고 할 수 있다.

데이터는 대체로 더럽다. 데이터를 실제로 받아보면 구멍이 나있거나 안에 100 ~ 200 값이 들어왔는데 쌩뚱맞게 50000이 들어가있는 경우도 있다. 제대로 로깅이 안된 것이다. 그래서 현장의 데이터를 받으면 일단 열어서 데이터를 보고 분포와 히스토그램 정도는 그려보는 것이 중요하다.

이 작업을 data cleaning이라고 하는데 data cleaning 작업이 다른 기술들을 적용하는 것 보다 오히려 성능을 훨씬 향상시키게 될 수 있다.


# 데이터의 측정
데이터는 사실 관측자에 의해서 재생산 되는 것이다.

같은 데이터도 관측자에 따라 다를 수 있고 관측자를 거칠 때 마다 재생산된다. (즉, 객관적인 데이터란 없음.)

그리고 상황에 따라 데이터에 이름을 붙여주는 data labling 작업이 필요하다.


# 데이터 샘플의 분포
내 시험 점수가 나오면 평균 점수와 최고점 정도가 궁금할 것이다. 그것은 다른 사람의 점수가 궁금해서가 아니라 내 점수의 수준이 궁금해서 물어본 것이다.

이처럼 데이터 샘플 하나는 의미가 없고 다른 데이터들 사이에서의 관계에서 의미가 생기는 것이다.

그 관계를 아는 것이 데이터의 분포를 아는 것이다.

근데 이 분포를 아는 것은 대부분의 상황에서 불가능한 일이다. 그래서 분포를 아는 대신 우회를 해서 분포를 알아야 하는데 그 문제에 대한 함수를 만드는 방식으로 우회한다. (ex. 사자 호랑이를 구분하는 함수)


# 데이터 일반화
데이터를 잘 일반화 하는 것이 중요하다.
일본에서 지진 데이터를 분석했을 때 진도 9.0이상의 지진이 13000년에 한 번씩 일어난다고 나왔는데 그 이상의 지진이 나와버려서 원자력 발전소가 무너졌다.

하지만 조금만 다르게 일반화 시켰다면 300년에 한 번씩 9.0이진이 일어난다고 나와서 대비를 하였을 것이다.

근데 머신러닝에서 빅 데이터를 넣으면 일반화가 잘 된다는 특징이 있다.


# 머신러닝


# 인공신경망 (ANNs)

# 머신러닝의 약점

- 이해할 수 없는 실수를 함
- 적대적 샘플과 패치

# AGI (General AI)를 향해


# AI risks
한 보고서에 따르면 superintelligent AI에 의한 인류멸망을 5%로 Nuclear war이 1%보다 훨씬 크게 나왔지만 교수님은 동의하기 힘들다고 하였다. 왜냐하면 현재 AGI보다는 툴로써의 AI에 대한 연구만을 많이 하기 때문에 AI자체가 악심을 품고 인류를 멸망시키기 보다는 인간이 악심을 품고 AI를 이용해서 안 좋은 일들을 저지를 확률이 더 높다.

현실적으로는
- 나쁜 의도를 가진 사람들에 의한 사용
- AI에 대한 열등감
- 사라지는 직업

등등의 이슈가 생길 수 있다.


특정 분야의 `문제가 잘 정의`되고 `데이터가 충분`하면
- AI는 반드시 사람(그 분야의 전문가)보다 더 나은 성능을 낼 것이다.
- 인공지능의 성능은 양질의 데이터확보가 관건이다.


사람과 AI는 경쟁이 아니라 함께 협력하는 관계이다.

# 질답

- 기획재정부 장관을 AI로 하면 오히려 더 좋은 결정을 내린다?

그러면 사람은 오히려 옛날 기계들이 하는 일처럼 data cleaning sampling을 하는 주객전도된 (주인 노예 역설) 상황이 나타날 수 있지 않을까?

엘레베이터가 생기고 사람이 아닌 기계가 승강기를 운전하고
자율운전AI가 생기고 사람이 아닌 기계가 차를 운전한 것 처럼
의사결정도 AI에게 되지 않을까?

근데 책임을 질 사람이 있어야하기 때문에 누군가는 있어야한다.
예를들어 AI의사가 독이든 약을 먹으라고 진단을 내리면 큰일이 나니가 최종결정권을 가진 의사가 필요할 것이다.

그럼 이제 인간은 뭘하게 되나? 잘 노는게 중요해지는 시대가 오지 않겠나? 아니면 인간에게 중요한 문제인 사랑이 무엇인가? 등의 철학적인 질문에 대한 해답을 찾는 철학이 더 중요해지지 않을까? 교수님도 잘 모르겠다고 하신다.